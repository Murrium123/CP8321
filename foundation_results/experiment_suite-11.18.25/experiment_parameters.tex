% Auto-generated parameter listing for experiment suite
\begin{itemize}
  \item Experiment: A1
  \item Description: Basic baseline (Dinov2)
  \item Encoder: facebook/dinov2-base
  \item Pooling: cls
  \item ConfigName: linear\_cls
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: A1
  \item Description: Basic baseline (Dinov2)
  \item Encoder: facebook/dinov2-base
  \item Pooling: cls
  \item ConfigName: mlp\_cls
  \item BaseConfig: mlp\_cls
  \item Classifier: mlp
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear + ReLU + Dropout(0.2) + Linear
  \item Neurons\_Per\_Layer: 768->384->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: A1
  \item Description: Basic baseline (Dinov2)
  \item Encoder: facebook/dinov2-base
  \item Pooling: cls
  \item ConfigName: rf\_cls
  \item BaseConfig: rf\_cls
  \item Classifier: rf
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: RandomForest
  \item Neurons\_Per\_Layer: 200 trees (sklearn)
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: A1
  \item Description: Basic baseline (Dinov2)
  \item Encoder: facebook/dinov2-base
  \item Pooling: mean
  \item ConfigName: linear\_cls\_mean
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: A1
  \item Description: Basic baseline (Dinov2)
  \item Encoder: facebook/dinov2-base
  \item Pooling: mean
  \item ConfigName: mlp\_cls\_mean
  \item BaseConfig: mlp\_cls
  \item Classifier: mlp
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear + ReLU + Dropout(0.2) + Linear
  \item Neurons\_Per\_Layer: 768->384->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: A1
  \item Description: Basic baseline (Dinov2)
  \item Encoder: facebook/dinov2-base
  \item Pooling: mean
  \item ConfigName: rf\_cls\_mean
  \item BaseConfig: rf\_cls
  \item Classifier: rf
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: RandomForest
  \item Neurons\_Per\_Layer: 200 trees (sklearn)
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: B1
  \item Description: Color jitter augmentation (Dinov2)
  \item Encoder: facebook/dinov2-base
  \item Pooling: cls
  \item ConfigName: linear\_cls
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.2
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: B1
  \item Description: Color jitter augmentation (Dinov2)
  \item Encoder: facebook/dinov2-base
  \item Pooling: mean
  \item ConfigName: linear\_cls\_mean
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.2
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: B2
  \item Description: Stain normalization+jitter (Dinov2)
  \item Encoder: facebook/dinov2-base
  \item Pooling: cls
  \item ConfigName: linear\_cls
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: Yes
  \item Stain\_Target\_Mean: 1.0,0.8,0.6
  \item Stain\_Target\_Std: 0.25,0.2,0.25
  \item Stain\_Jitter\_Std: 0.08
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: B2
  \item Description: Stain normalization+jitter (Dinov2)
  \item Encoder: facebook/dinov2-base
  \item Pooling: mean
  \item ConfigName: linear\_cls\_mean
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: Yes
  \item Stain\_Target\_Mean: 1.0,0.8,0.6
  \item Stain\_Target\_Std: 0.25,0.2,0.25
  \item Stain\_Jitter\_Std: 0.08
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: C1
  \item Description: Phikon baseline
  \item Encoder: owkin/phikon
  \item Pooling: cls
  \item ConfigName: linear\_cls
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: C1
  \item Description: Phikon baseline
  \item Encoder: owkin/phikon
  \item Pooling: cls
  \item ConfigName: mlp\_cls
  \item BaseConfig: mlp\_cls
  \item Classifier: mlp
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear + ReLU + Dropout(0.2) + Linear
  \item Neurons\_Per\_Layer: 768->384->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: C1
  \item Description: Phikon baseline
  \item Encoder: owkin/phikon
  \item Pooling: mean
  \item ConfigName: linear\_cls\_mean
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: C1
  \item Description: Phikon baseline
  \item Encoder: owkin/phikon
  \item Pooling: mean
  \item ConfigName: mlp\_cls\_mean
  \item BaseConfig: mlp\_cls
  \item Classifier: mlp
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear + ReLU + Dropout(0.2) + Linear
  \item Neurons\_Per\_Layer: 768->384->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: C2
  \item Description: Phikon + simple transforms
  \item Encoder: owkin/phikon
  \item Pooling: cls
  \item ConfigName: linear\_cls
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: Yes
  \item Stain\_Target\_Mean: 1.0,0.8,0.6
  \item Stain\_Target\_Std: 0.25,0.2,0.25
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.15
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: C2
  \item Description: Phikon + simple transforms
  \item Encoder: owkin/phikon
  \item Pooling: mean
  \item ConfigName: linear\_cls\_mean
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 0
  \item Early\_Stop\_Metric: Disabled
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: Yes
  \item Stain\_Target\_Mean: 1.0,0.8,0.6
  \item Stain\_Target\_Std: 0.25,0.2,0.25
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.15
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: D1
  \item Description: Dinov2 LoRA vs frozen
  \item Encoder: facebook/dinov2-base
  \item Pooling: cls
  \item ConfigName: linear\_cls
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 2
  \item Early\_Stop\_Metric: accuracy
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: D1
  \item Description: Dinov2 LoRA vs frozen
  \item Encoder: facebook/dinov2-base
  \item Pooling: cls
  \item ConfigName: linear\_cls\_lora
  \item BaseConfig: linear\_cls\_lora
  \item Classifier: linear
  \item Use\_LoRA: Yes
  \item LoRA\_Rank: 8
  \item LoRA\_Alpha: 16.0
  \item LoRA\_Dropout: 0.05
  \item LoRA\_TargetModules: auto (query/key/value for ViT backbones)
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 2
  \item Early\_Stop\_Metric: accuracy
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: D2
  \item Description: Phikon LoRA vs frozen
  \item Encoder: owkin/phikon
  \item Pooling: cls
  \item ConfigName: linear\_cls
  \item BaseConfig: linear\_cls
  \item Classifier: linear
  \item Use\_LoRA: No
  \item LoRA\_Rank: -
  \item LoRA\_Alpha: -
  \item LoRA\_Dropout: -
  \item LoRA\_TargetModules: -
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 2
  \item Early\_Stop\_Metric: accuracy
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}

\begin{itemize}
  \item Experiment: D2
  \item Description: Phikon LoRA vs frozen
  \item Encoder: owkin/phikon
  \item Pooling: cls
  \item ConfigName: linear\_cls\_lora
  \item BaseConfig: linear\_cls\_lora
  \item Classifier: linear
  \item Use\_LoRA: Yes
  \item LoRA\_Rank: 8
  \item LoRA\_Alpha: 16.0
  \item LoRA\_Dropout: 0.05
  \item LoRA\_TargetModules: auto (query/key/value for ViT backbones)
  \item Head\_Layers: Linear
  \item Neurons\_Per\_Layer: 768->4
  \item Epochs: 6
  \item Batch\_Size: 16
  \item Learning\_Rate: 0.0001
  \item Early\_Stop\_Patience: 2
  \item Early\_Stop\_Metric: accuracy
  \item Folds: 1,2,3,4
  \item Stain\_Normalize: No
  \item Stain\_Target\_Mean: -
  \item Stain\_Target\_Std: -
  \item Stain\_Jitter\_Std: 0.0
  \item Color\_Jitter: 0.0
  \item Color\_Contrast\_Cutoff: 0.0
\end{itemize}
